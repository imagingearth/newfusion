# swath_download.R
# Version 1.0.1
# Tools
#
# Project: Fusion
# By Xiaojing Tang
# Created On: 11/9/2014
# Last Update: 11/24/2014
#
# Input Arguments: 
#   file - a text file that is generated by LAADS website.
#   output - the output directory for saving the data
#   
# Output Arguments: NA
#
# Usage: 
#   1.Install package RCurl and bitops.
#   2.Search for swath data on the LAADS website.
#   3.Submit your order.
#   3.Save the order page with all the files to be downloaded as a text file.
#   4.Run the script with the text file after the order is processed.
#
# Version 1.0 - 11/9/2014
#   This script downloads MODIS Swath data
#
# Updates of Version 1.0.1 - 11/12/2014
#   1.Bug fixed.
#   
# Created on Github on 11/4/2014, check Github Commits for updates afterwards.
#----------------------------------------------------------------

# library
library(RCurl)

# sourcing
script <- getURL('https://raw.githubusercontent.com/xjtang/rTools/master/web_tools.R',ssl.verifypeer=F)
eval(parse(text=script),envir=.GlobalEnv)
sourceURL('https://raw.githubusercontent.com/xjtang/rTools/master/text_tools.R')

# main function
swathDownload <- function(webFile,output){

  # set base url of usgs ftp
  baseURL <- 'ftp://ladsweb.nascom.nasa.gov/allData'

  # check input html file
  if(!file.exists(webFile)){
    cat('Can not find input HTML file:\n')
    cat(webFile,'\n')
    cat('Please check again.\n')
    return(-1)
  }

  # remove the trailing / from the output directory
  if(strRight(output,1) == '/'){
    output <- trimRight(output,1)
  }

  # check if output directory exist
  if(!file.exists(output)){
    cat('Output directory does not exist, creating one.\n')
    dir.create(output)
  }

  # read in html file
  imgList <- readLines(webFile,warn=F)
  
  # pre-process list
  pat <- '^.*(M.*D09.*hdf).*$'
  imgList <- gsub(pat, '\\1', imgList[grepl(pat,imgList)])

  # count numbers 
  n <- length(imgList)

  # loop though the list
  for(i in 1:n){
  
    # progress
    pgs <- paste('(',i,'/',n,')',sep='')
    
    # parse the file name
    img <- unlist(strsplit(imgList[i],'.',fixed=T))
    col <- as.integer(img[4])
    prod <- img[1]
    year <- substr(img[2],2,5)
    day <- substr(img[2],6,9)
    
    # forge url and output file
    fullURL <- paste(baseURL,col,prod,year,day,imgList[i],sep='/')
    outFile <- paste(output,imgList[i],sep='/')
    
    # check if file exist on ftp
    if(!url.exists(fullURL)){
      cat(pgs,'File does not exist on the ftp: ',fullURL)
      cat('\nSkip this one\n')
      next
    }
    
    # check if file already exist in output
    if(file.exists(outFile)){
      cat(pgs,'File already exist in output directory: ',outFile)
      cat('\nSkip this one\n')
      next
    }
    
    # download
    cat(pgs,'Downloading from: ',fullURL)
    try(binDownload(fullURL,outFile))
    cat('...done\n')

    # garbage collection
    gc()

  }

  # done
  cat('all done\n')

}


